{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2c0c13",
   "metadata": {},
   "source": [
    "# LAB 2: Evaluating Generative Models\n",
    "\n",
    "In this lab, we are going to practice how to evaluate generative models.\n",
    "The evaluation method is not limited to diffusion models, in fact, deep generative models such as GAN and Flow use this method widely.\n",
    "\n",
    "<span style=\"color:red\">It is necessary to have a GPU to complete LAB2.</span><br>\n",
    "<span style=\"color:red\">Its efficacy will not affect your completion of this lab. Colab free plan also works.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2d6e27",
   "metadata": {},
   "source": [
    "## Install Packages\n",
    "\n",
    "Install `torch`, `torchvision` and `pytorch_gan_metrics`.\n",
    "\n",
    "- Colab\n",
    "\n",
    "    Use system default `torch` and `torchvision` to avoid hardware incompatibility.\n",
    "    ```\n",
    "    pip install pytorch_gan_metrics\n",
    "    ```\n",
    "\n",
    "- Custom environment (include `conda` users)\n",
    "\n",
    "    Install all packages from pypi.\n",
    "    ```\n",
    "    pip install torch torchvision pytorch_gan_metrics\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d6f513",
   "metadata": {},
   "source": [
    "## Checkpoint 1 - Generating Fake Images\n",
    "- Use `torch` to generate some noise as images.\n",
    "- Use `torchvision.utils.save_image` to save `torch.Tensor` as an `png` image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53f9e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "num_images = 1000\n",
    "os.makedirs('./images', exist_ok=True)\n",
    "for i in range(num_images):\n",
    "    image = torch.randn((3, 28, 28))  # random normal\n",
    "    image = torch.clamp(image, min=-1, max=1)  # clamp [-1, 1]\n",
    "    image = (image + 1) / 2  # shift [0 , 1]\n",
    "    path = os.path.join(f'./images/{i:05d}.png')\n",
    "    save_image(image, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fea212",
   "metadata": {},
   "source": [
    "## (Optional) Check the Number of Files in `./images` (Unix Only)\n",
    "- The number of files should be 1000\n",
    "- Note that the number of generated images in spec of HW3 is 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9979c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "!ls ./images | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42ad6b7",
   "metadata": {},
   "source": [
    "## Checkpoint 2 - Evaluate Generated Images in Console\n",
    "\n",
    "1. Download `mnist.npz` from E3 [Homework 3 - Source Code](https://e3.nycu.edu.tw/mod/assign/view.php?id=329368).\n",
    "2. Refer to the example in page 5 of `HW3.pdf`.\n",
    "3. Calculate the FID between generated images in `./images` and our dataset (`mnist.npz`).\n",
    "\n",
    "The calculated FID *must* be around $400$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3d974a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.208115861448908 0.0140026323908044 390.1258565489452                          \n"
     ]
    }
   ],
   "source": [
    "!python -m pytorch_gan_metrics.calc_metrics \\\n",
    "    --path ./images \\\n",
    "    --stats mnist.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd166708",
   "metadata": {},
   "source": [
    "## Checkpoint 3 - Evaluate Generated Images at Runtime\n",
    "- Use `torchvision.io.read_image` to load all images into memory one by one.\n",
    "- Use `pytorch_gan_metrics.get_fid` to calculate FID between generated images in `./images` and our dataset (`mnist.npz`).\n",
    "\n",
    "    The following is the document about how to use `get_fid` for reference.\n",
    "    ```python\n",
    "    from pytorch_gan_metrics import get_fid\n",
    "\n",
    "    images = ...                                    # [N, 3, H, W] normalized to [0, 1]\n",
    "    FID = get_fid(images, 'path/to/statistics.npz') # Frechet Inception Distance\n",
    "    ```\n",
    "\n",
    "The output FID should be the same as Checkpoint 2 (round to two decimal places)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "536956d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390.12586\n"
     ]
    }
   ],
   "source": [
    "from pytorch_gan_metrics import get_fid\n",
    "from torchvision.io import read_image\n",
    "\n",
    "images = []\n",
    "for i in range(num_images):\n",
    "    path = os.path.join(f'./images/{i:05d}.png')\n",
    "    image = read_image(path) / 255.\n",
    "    images.append(image)\n",
    "images = torch.FloatTensor(torch.stack(images, dim=0))\n",
    "FID = get_fid(images, 'mnist.npz')\n",
    "print(f'{FID:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b21df",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Use `torchvision` to Save Grid Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "202e10ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPIAAADyCAIAAAD4Cg/zAAAFYklEQVR4nO3c0ecQZh/G4btXoygaRdEoFu2gWBRFURSNRVEUi0axKIqiUQdFUSw2isbGYlEUGxvFxsZGY6MONjaKoiiKomj0nvz+hOf1e92u6w+4n5PPwffoSQD4/zflf/3A1KlTh2/++++/SaZNmzZ8+eXLl0lmzJgxfPn58+dJZs2aNXz56dOnSWbPnj18+fHjx0nmzp07fPnhw4dJ5s+fP3z5/v37Sf4zfBcmnawpJGsKyZpCsqaQrCkkawrJmkKyppCsKSRrCsmaQrKmkKwpJGsKyZpCsqaQrCkkawrJmkKyppCsKSRrCsmaQrKmkKwpJGsAYFJM/Ji6YMGC4dN3795N8vbbbw9f/ueff5IsXrx4+PJff/2VZMmSJcOXb9++neTdd98dvvzHH38kWb58+fDl3377LcnKlSuHL//6669JVq9ePXz5559/jtuaSrKmkKwpJGsKyZpCsqaQrCkkawrJmkKyppCsKSRrCsmaQrKmkKwpJGsKyZpCsqaQrCkkawrJmkKyppCsKSRrCsmaQrKmkKwBgEkx8WPq2rVrh0//+OOPSdavXz98+caNG0k2btw4fPn7779P8v777w9f/vbbb5Ns3rx5+PK1a9eSbN26dfjylStXkmzfvn348qVLl5J88MEHw5cvXrwYtzWVZE0hWVNI1hSSNYVkTSFZU0jWFJI1hWRNIVlTSNYUkjWFZE0hWVNI1hSSNYVkTSFZU0jWFJI1hWRNIVlTSNYUkjWFZE0hWQMAk2Lix9Rdu3YNn/7yyy+T7N69e/jy559/nuSjjz4avnz+/Pkk+/btG7782WefJTlw4MDw5bNnzyY5dOjQ8OUzZ84kOXLkyPDlU6dOJTl69Ojw5RMnTsRtTSVZU0jWFJI1hWRNIVlTSNYUkjWFZE0hWVNI1hSSNYVkTSFZU0jWFJI1hWRNIVlTSNYUkjWFZE0hWVNI1hSSNYVkTSFZU0jWAMCkmPgx9fjx48Onjx07luTkyZPDlz/++OMkp0+fHr58+PDhJJ988snw5YMHDyb59NNPhy/v378/yblz54Yv7927N8mFCxeGL+/ZsyfJF198MXz5ww8/jNuaSrKmkKwpJGsKyZpCsqaQrCkkawrJmkKyppCsKSRrCsmaQrKmkKwpJGsKyZpCsqaQrCkkawrJmkKyppCsKSRrCsmaQrKmkKwBgEkx8WPqV199NXx6586dSb7++uvhyzt27Ehy+fLl4cvbtm1LcvXq1eHLW7ZsSfLNN98MX960aVOS7777bvjye++9l+T69evDlzds2JDkhx9+GL68bt26uK2pJGsKyZpCsqaQrCkkawrJmkKyppCsKSRrCsmaQrKmkKwpJGsKyZpCsqaQrCkkawrJmkKyppCsKSRrCsmaQrKmkKwpJGsKyRoAmBQTP6b+9NNPw6fXrFmT5Jdffhm+vGrVqiQ3b94cvrxixYokv//++/DlZcuWJbl169bw5aVLlyb5888/hy+/8847Sf7+++/hy4sWLUpy586d4csLFy6M25pKsqaQrCkkawrJmkKyppCsKSRrCsmaQrKmkKwpJGsKyZpCsqaQrCkkawrJmkKyppCsKSRrCsmaQrKmkKwpJGsKyZpCsqaQrAGASTHxY+q9e/eGT7/11ltJHjx4MHx53rx5SR49ejR8ec6cOUmePHkyfPnNN99M8uzZs+HLM2fOTPLixYvhy9OnT0/y6tWr4ctvvPFGktevXw9fnjJlStzWVJI1hWRNIVlTSNYUkjWFZE0hWVNI1hSSNYVkTSFZU0jWFJI1hWRNIVlTSNYUkjWFZE0hWVNI1hSSNYVkTSFZU0jWFJI1hWQNAEyK/wJAGL65UypHcwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "colors = torch.linspace(0, 1, 64)\n",
    "images = colors.view(64, 1, 1, 1).expand(64, 3, 28, 28)\n",
    "save_image(images, 'example.png')\n",
    "display(Image(filename='example.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('lab2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd2b859c69e2c5882484d057cb49e647d044fab7370fee7307f1d71f03303abd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
